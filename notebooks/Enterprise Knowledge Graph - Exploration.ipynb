{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores the steps involved in construction of a knowledge graph from unstructured text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Toolkits and Packages\n",
    "### Ubuntu packages\n",
    "1. sudo apt-get install graphviz\n",
    "2. python\n",
    "3. Stanford Core NLP Toolkit\n",
    "4. Java 1.8 +\n",
    "\n",
    "\n",
    "### Python Packages\n",
    "1. pycorenlp - A python wrapper for the Stanford Core NLP Toolkit\n",
    "2. graphviz - Toolkit for quickly visualising the triple output in graph form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the code, ensure that the Stanford Core NLP Server is up and running. To start the server use the below command (from the Stanford Core NLP Directory)\n",
    "> java -mx8g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Getting Triples from Unstructured Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "from graphviz import Source\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP(server_url=\"http://localhost:9000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/shyam/consciousness.txt\"\n",
    "with open(filename, 'r') as myfile:\n",
    "    text=myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = nlp.annotate(str.lower(text), properties={'annotators':'tokenize,ssplit,pos,lemma,depparse,natlog,ner,coref,openie',\n",
    "                                 'outputFormat':'json',\"openie.resolve_coref\":\"true\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the output is obtained from the server, we parse the output to extract the open IE section.\n",
    "For each sentence, we then extract the triple in the order subject, relation and object and aggregate it to a list.\n",
    "This final list contains the list of all triples extracted from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples_set = [] \n",
    "for sentence in output['sentences']:\n",
    "    for triples in sentence['openie']:\n",
    "        triple = [triples['subject'],triples['relation'],triples['object']]\n",
    "        triples_set.append(triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['consciousness', 'is', 'state'],\n ['consciousness', 'is state of', 'awareness'],\n ['it', 'is', 'have'],\n ['it', 'be', 'consciousness'],\n ['many philosophers', 'believe despite', 'difficulty in definition']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples_set[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the triples using graphviz\n",
    "The below section of code is used to generate a graph object for visualisng the generated triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_folder = \"/tmp/openie/\"\n",
    "graph = list()\n",
    "graph.append('digraph prof {')\n",
    "graph.append('rankdir = LR;')\n",
    "graph.append('ratio = fill;')\n",
    "graph.append('node [style=filled];')\n",
    "\n",
    "for er in triples_set:\n",
    "    graph.append('\"{}\" -> \"{}\" [ label=\"{}\" ];'.format(er[0], er[2], er[1]))\n",
    "graph.append('}')\n",
    "out_dot = tmp_folder + 'out.dot'\n",
    "with open(out_dot, 'w') as output_file:\n",
    "    output_file.writelines(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_img = Source.from_file(out_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(graph,) = pydot.graph_from_dot_file(out_dot)\n",
    "graph.write_png('graph_result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x7f23dec4fb00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
